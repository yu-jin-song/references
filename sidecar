[‎standalone/single_control_plane/deploy-cp-cluster.sh]
source cp-cluster-vars.sh
source package-install.sh
source cp-cluster-setting.sh
source cp-cluster-install.sh

[‎standalone/single_control_plane/cp-cluster-setting.sh]
cp roles/kubernetes-apps/metrics_server/defaults/main.yml.ori roles/kubernetes-apps/metrics_server/defaults/main.yml
CONFIG_FILE=inventory/mycluster/hosts.yaml python3 contrib/inventory_builder/inventory.py ${IPS[@]}

=========================================================================================================================

[standalone/single_control_plane/roles/download/defaults/main.yml]
/* 다음 부분 수정 : v0.6.1 -> v0.6.4 */
...

metrics_server_version: "v0.6.4"

=========================================================================================================================

[standalone/single_control_plane/cluster.yml]
/* 다음 부분 주석처리 */
...

- hosts: kube_control_plane
  gather_facts: False
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  environment: "{{ proxy_disable_env }}"
  roles:
    - { role: kubespray-defaults }
    - { role: paasta-cp/istio }

...

- hosts: kube_control_plane
  gather_facts: False
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  environment: "{{ proxy_disable_env }}"
  roles:
    - { role: kubespray-defaults }
    - { role: paasta-cp/kubeflow }



=========================================================================================================================
=========================================================================================================================
## istio oerator 설치(sidecar-deployment 내에 위치 필요)
1. istioctl 설치
curl -L https://git.io/getLatestIstio | ISTIO_VERSION=1.12.6 sh -
cd istio-1.12.6
sudo cp bin/istioctl /usr/local/bin/istioctl

2. istio operator 설치
git clone https://github.com/istio/istio.git -b 1.12.6 istio-operator
cd istio-operator
/* namespace 생성 */
[istio-namespace.yml]
apiVersion: v1
kind: Namespace
metadata:
  labels:
    cloudfoundry.org/istio_version: 1.12.6
    cf-for-k8s.cloudfoundry.org/istio-system-ns: ""
  name: istio-system

kubectl apply -f istio-namespace.yml

/* operator 설치 */
[istio-operator-values.yml]
revision: "1-12-6"
operatorNamespace: istio-operator
watchedNamespaces: istio-system
operator:
  resources:
    limits:
      cpu: 4
      memory: 4Gi
    requests:
      cpu: 2
      memory: 2G

[istio-operator/manifests/charts/istio-operator/templates/deployment.yaml]
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: {{.Release.Namespace}}
  name: istio-operator{{- if not (eq .Values.revision "") }}-{{ .Values.revision }}{{- end }} // 이 부분 아래에 다음 내용 추가
  labels:
    cloudfoundry.org/istio_version: 1.12.6
...

/* file 수정없이도 적용되는지 확인 필요 */
[istio-operator/manifests/charts/istio-operator/files/gen-operator.yaml]
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: istio-operator
  name: istio-operator	// 이 부분 아래에 다음 내용 추가
  labels:
    cloudfoundry.org/istio_version: 1.12.6
...

helm upgrade -i istio-operator ./istio-operator/manifests/charts/istio-operator -f istio-operator-values.yaml -n istio-system

/* control plane 설치(cni enabled) */
[istio-profile.yml]
---
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
metadata:
  namespace: istio-system
  name: istio-controlplane
spec:
  components:
    cni:
      enabled: true

kubectl apply -f istio-profile.yml


=========================================================================================================================
=========================================================================================================================

[sidecar-deployment/config/istio/add-istio-injection.yml]
/* 다음 부분 수정 : enabled -> 1-12-6 */
...

istio-injection: 1-12-6

[sidecar-deployment/config/istio/istio-generated/xxx-generated-istio.yml]
/* 다음 부분 수정 : false -> true */
...

      "istio_cni": {
        "enabled": true
      },

[sidecar-deployment/config/system-namespace.yml]
apiVersion: v1
kind: Namespace
metadata:
  name: #@ system_namespace()
  labels:
    cf-for-k8s.cloudfoundry.org/cf-system-ns: ""  // 아래에 다음 내용 추가
    #@ if system_namespace() == "cf-system":
    pod-security.kubernetes.io/enforce: privileged
    #@ end
...

==================================================================================================================

kapp: Error: waiting on reconcile builder/cf-default-builder (kpack.io/v1alpha1) namespace: cf-workloads-staging:
  Finished unsuccessfully (Encountered failure condition Ready == False:  (message: GET https://auth.docker.io/token?scope=repository%3Apaketobuildpacks%2Fbuild%3Apull&service=registry.docker.io: unexpected status code 401 Unauthorized: {"details":"incorrect username or password"}

manager 2023-08-04T06:13:48.280Z    ERROR    controller-runtime.controller    Reconciler error    {"controller": "periodicsync", "request": "cf-system/cf-api-periodic-route-sync", "error": "error listing routes from CF API: failed to list routes, HTTP error: Get \"http://capi.cf-system.svc.cluster.local/v3/routes?per_page=5000&include=space,domain\": dial tcp 10.233.61.231:80: connect: connection refused"}

$ TOKEN=$(curl "https://auth.docker.io/token?service=registry.docker.io&scope=repository:ratelimitpreview/test:pull" | jq -r .token)

$ curl --head -H "Authorization: Bearer $TOKEN" https://registry-1.docker.io/v2/ratelimitpreview/test/manifests/latest 2>&1 | grep RateLimit




==================

All that is needed is Linux kernel version 5.9 or newer on both the server and client, then mount with NFS version 4.2 or newer. Support for extended attributes is enabled automatically when both server and client support nfs 4.2.
I have kernel version 5.15.16 on both my server and client with nfs-utils-2.5.4-r3, and it is working for me:

## NFS Server : /etc/exports
/  192.168.0.42(rw,subtree_check,no_root_squash)

## NFS Client : /etc/fstab
192.168.0.42:/  /mnt/slowpc  nfs  noatime,nodiratime,noauto,hard,rsize=1048576,wsize=1048576,timeo=60,retrans=60  0 0

## NFS Client
# mount | grep /mnt/slowpc
192.168.0.42:/ on /mnt/slowpc type nfs4 (rw,noatime,nodiratime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=60,retrans=60,sec=sys,local_lock=none)
# cd /mnt/slowpc/tmp
# touch file
# printf bar | attr -s foo file
Attribute "foo" set to a 3 byte value for file:
bar
# attr -l file
Attribute "foo" has a 3 byte value for file

## NFS Server
# attr -l /tmp/file
Attribute "foo" has a 3 byte value for /tmp/file

At https://lwn.net/Articles/799185/ it is mentioned that the new mount option user_xattr is required. However the current nfs utilities do not support that option. Fortunately user_xattr is enabled automatically when possible.

# mount -o user_xattr /mnt/test
mount.nfs: an incorrect mount option was specified
# tail -n 1 /var/log/messages
Jan 30 02:51:08 utl01 kernel: nfs: Unknown parameter 'user_xattr'
